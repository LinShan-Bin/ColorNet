{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/medium/train_all.json', 'r') as f:\n",
    "    labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(labels[\"601421234332\"], sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --name clothes_monet --model monet --dataroot '../dataset/medium' --gpu_ids -1 --batch_size 1 --num_slots 3 --input_nc 3 --z_dim 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format('./merge_sgns_bigram_char300.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53147215 0.55452967 0.6240347 0.34335798 0.55790067\n"
     ]
    }
   ],
   "source": [
    "red = '红'\n",
    "reds = '红色'\n",
    "white = '白'\n",
    "black = '黑'\n",
    "pink = '粉'\n",
    "vred = word2vec[red]\n",
    "vreds = word2vec[reds]\n",
    "vwhite = word2vec[white]\n",
    "vblack = word2vec[black]\n",
    "vpink = word2vec[pink]\n",
    "covrw = np.dot(vred, vwhite) / (np.linalg.norm(vred) * np.linalg.norm(vwhite))\n",
    "covrk = np.dot(vred, vblack) / (np.linalg.norm(vred) * np.linalg.norm(vblack))\n",
    "covwk = np.dot(vwhite, vblack) / (np.linalg.norm(vwhite) * np.linalg.norm(vblack))\n",
    "covpr = np.dot(vpink, vred) / (np.linalg.norm(vpink) * np.linalg.norm(vred))\n",
    "covrr = np.dot(vreds, vred) / (np.linalg.norm(vreds) * np.linalg.norm(vred))\n",
    "print(covrw, covrk, covwk, covpr, covrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('黄', 0.6442532539367676), ('黑', 0.6240347623825073), ('白红', 0.6085060238838196), ('白棕', 0.5869372487068176), ('紫', 0.5859890580177307), ('白就', 0.5846289396286011), ('米白', 0.5840865969657898), ('白再', 0.5804263949394226), ('白配', 0.5757509469985962), ('白紫', 0.5732380151748657), ('纯白', 0.5731773376464844), ('雪白', 0.5714313387870789), ('白两', 0.571010947227478), ('白衬', 0.5649784803390503), ('灰白', 0.563745379447937), ('不白', 0.5636759996414185), ('麻白', 0.5581346750259399), ('黄白', 0.556592583656311), ('白格', 0.5539156198501587), ('白几', 0.5526947975158691)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linshan/miniforge3/envs/prml/lib/python3.9/site-packages/gensim/models/keyedvectors.py:850: RuntimeWarning: invalid value encountered in true_divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n"
     ]
    }
   ],
   "source": [
    "red = '白'\n",
    "neighbors = word2vec.most_similar(red, topn=20)\n",
    "print(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "泡泡\n",
      "粉\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "words_j = jieba.cut('泡泡粉', cut_all=False)\n",
    "vecs = []\n",
    "for word in words_j:\n",
    "    print(word)\n",
    "    vecs.append(word2vec[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[164, 166, 167,  ..., 218, 218, 219],\n",
      "          [178, 178, 178,  ..., 218, 219, 219],\n",
      "          [184, 182, 180,  ..., 218, 218, 218],\n",
      "          ...,\n",
      "          [157, 152, 144,  ..., 126, 127, 123],\n",
      "          [151, 125, 134,  ..., 119, 124, 122],\n",
      "          [130, 138, 153,  ..., 119, 126, 123]],\n",
      "\n",
      "         [[138, 140, 143,  ..., 202, 202, 203],\n",
      "          [152, 152, 152,  ..., 202, 203, 203],\n",
      "          [158, 156, 154,  ..., 202, 202, 202],\n",
      "          ...,\n",
      "          [111, 106,  98,  ...,  79,  78,  74],\n",
      "          [104,  78,  87,  ...,  72,  75,  73],\n",
      "          [ 83,  91, 106,  ...,  72,  77,  74]],\n",
      "\n",
      "         [[105, 107, 109,  ..., 177, 177, 178],\n",
      "          [119, 119, 119,  ..., 177, 178, 178],\n",
      "          [125, 123, 121,  ..., 177, 177, 177],\n",
      "          ...,\n",
      "          [ 59,  54,  46,  ...,  25,  20,  15],\n",
      "          [ 52,  26,  35,  ...,  18,  17,  14],\n",
      "          [ 31,  39,  54,  ...,  18,  19,  15]]]], dtype=torch.uint8)\n",
      "[('杏色',), ('深蓝色',)]\n",
      "('深蓝色',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/0w/j3hd49492bncw4zlczqbyrmr0000gn/T/jieba.cache\n",
      "Loading model cost 0.322 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[230, 223, 215,  ..., 196, 202, 209],\n",
      "          [217, 213, 207,  ..., 191, 191, 207],\n",
      "          [216, 213, 207,  ..., 193, 200, 200],\n",
      "          ...,\n",
      "          [152, 146, 164,  ..., 178, 132, 146],\n",
      "          [157, 154, 148,  ..., 138, 177, 181],\n",
      "          [151, 164, 147,  ..., 172, 165, 191]],\n",
      "\n",
      "         [[213, 206, 198,  ..., 177, 183, 192],\n",
      "          [200, 196, 190,  ..., 172, 172, 188],\n",
      "          [199, 196, 190,  ..., 174, 181, 181],\n",
      "          ...,\n",
      "          [152, 146, 164,  ..., 182, 136, 150],\n",
      "          [157, 154, 148,  ..., 144, 183, 187],\n",
      "          [151, 164, 147,  ..., 178, 171, 199]],\n",
      "\n",
      "         [[197, 190, 182,  ..., 160, 166, 174],\n",
      "          [184, 180, 174,  ..., 155, 155, 171],\n",
      "          [183, 180, 174,  ..., 157, 164, 164],\n",
      "          ...,\n",
      "          [150, 144, 162,  ..., 194, 148, 162],\n",
      "          [155, 152, 146,  ..., 156, 197, 201],\n",
      "          [149, 162, 145,  ..., 192, 185, 212]]],\n",
      "\n",
      "\n",
      "        [[[242, 242, 243,  ..., 243, 243, 244],\n",
      "          [242, 242, 242,  ..., 240, 240, 241],\n",
      "          [242, 242, 242,  ..., 239, 239, 240],\n",
      "          ...,\n",
      "          [222, 223, 223,  ..., 241, 241, 241],\n",
      "          [222, 223, 223,  ..., 241, 241, 241],\n",
      "          [223, 223, 223,  ..., 241, 241, 241]],\n",
      "\n",
      "         [[234, 234, 235,  ..., 235, 235, 236],\n",
      "          [234, 234, 234,  ..., 232, 232, 233],\n",
      "          [234, 234, 234,  ..., 231, 231, 232],\n",
      "          ...,\n",
      "          [205, 206, 206,  ..., 229, 229, 229],\n",
      "          [205, 206, 206,  ..., 229, 229, 229],\n",
      "          [206, 206, 206,  ..., 229, 229, 229]],\n",
      "\n",
      "         [[215, 215, 216,  ..., 214, 214, 215],\n",
      "          [215, 215, 215,  ..., 211, 211, 212],\n",
      "          [215, 215, 215,  ..., 210, 210, 211],\n",
      "          ...,\n",
      "          [179, 180, 180,  ..., 203, 205, 205],\n",
      "          [179, 180, 180,  ..., 203, 205, 205],\n",
      "          [180, 180, 180,  ..., 203, 205, 205]]]], dtype=torch.uint8)\n",
      "tensor([[[-0.0396, -0.4817,  0.6223,  ...,  0.1229,  0.0492, -0.2733],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0396, -0.4817,  0.6223,  ...,  0.1229,  0.0492, -0.2733],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])\n",
      "tensor([[1],\n",
      "        [1]])\n",
      "tensor([[[[255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          ...,\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255]],\n",
      "\n",
      "         [[255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          ...,\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255]],\n",
      "\n",
      "         [[255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          ...,\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255]]],\n",
      "\n",
      "\n",
      "        [[[255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          ...,\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255]],\n",
      "\n",
      "         [[255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          ...,\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255]],\n",
      "\n",
      "         [[255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          ...,\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255],\n",
      "          [255, 255, 255,  ..., 255, 255, 255]]]], dtype=torch.uint8)\n",
      "tensor([[[-0.0127, -1.0770,  0.4011,  ...,  0.2754,  0.7160, -0.1083],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0565, -1.2037,  0.4320,  ...,  0.4482,  0.3166, -0.5033],\n",
      "         [ 0.3689, -0.7928,  0.6480,  ...,  0.5737,  0.5669, -0.5511],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])\n",
      "tensor([[1],\n",
      "        [0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linshan/ColorNet/utils/word_embedding.py:39: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/miniforge3/conda-bld/pytorch-recipe_1647804326539/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  embedded = torch.tensor(embedded)\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from utils import *\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "DATA_PATH = './dataset/medium/'\n",
    "\n",
    "# train_dataset = ColorfulClothes(DATA_PATH, True)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "# for i, (image, label) in enumerate(train_loader):\n",
    "#     pprint(image)\n",
    "#     pprint(label)\n",
    "#     if i == 0:\n",
    "#         break\n",
    "    \n",
    "unfolded = ColorfulClothesUnfolded(DATA_PATH, True)\n",
    "loader = DataLoader(unfolded, batch_size=1, shuffle=True)\n",
    "for i, (image, optional_tags, label) in enumerate(loader):\n",
    "    pprint(image)\n",
    "    pprint(optional_tags)\n",
    "    pprint(label)\n",
    "    if i == 0:\n",
    "        break\n",
    "\n",
    "bin = ColorfulClothesBin(DATA_PATH, embed=Embed(), train=True)\n",
    "bin_loader = DataLoader(bin, batch_size=2, shuffle=True)\n",
    "for i, (image, tag, label) in enumerate(bin_loader):\n",
    "    pprint(image)\n",
    "    pprint(tag)\n",
    "    pprint(label)\n",
    "    if i == 1:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21bac44a2579471fb422f24ada59b7755552e433b846d8d3e893e5456907b211"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('prml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
